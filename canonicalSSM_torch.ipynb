{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "baaff332-22f6-4ed0-a94f-9d19b068770b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "from collections.abc import Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ed1d768-e46f-4911-9e30-9d6091aded87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_SSM(N : int) -> (torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor):\n",
    "    A = torch.autograd.Variable(torch.rand(size=(N,N)), requires_grad = True)\n",
    "    B = torch.autograd.Variable(torch.rand(size=(N,1)), requires_grad = True)\n",
    "    C = torch.autograd.Variable(torch.rand(size=(1,N)), requires_grad = True)\n",
    "    D = torch.autograd.Variable(torch.rand(size=(1,1)), requires_grad = True)\n",
    "    return A, B, C, D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c913ebed-b17c-4993-a4c4-be749db92f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "A, B, C, D = random_SSM(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34e5a72b-292c-43a7-bda5-6edbf96b7ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = torch.zeros((1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f60b605e-0171-4aec-acd1-793ea3007d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = torch.tensor(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53248f90-d07b-45a7-b111-d45f5b2f6f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretize(\n",
    "    A : torch.Tensor, B : torch.Tensor, C : torch.Tensor, D : torch.Tensor, delta : torch.Tensor\n",
    ") -> (torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor):\n",
    "    \"\"\"Discretizes SSM using bilinear model\n",
    "\n",
    "    parameters:\n",
    "        A: (NxN) transition matrix in latent\n",
    "        B: (Nx1) projection matrix to latent\n",
    "        C: (1xN) projection matrix from latent to output\n",
    "        D: (1x1) skip connection from input to output\n",
    "        delta: time step, ensure sufficient smallness\n",
    "    \"\"\"\n",
    "    Cbar = C\n",
    "    Dbar = D\n",
    "    N = A.shape[0]\n",
    "    Bl = torch.linalg.inv(torch.eye(N) - delta / 2 * A)\n",
    "    Abar = Bl@(torch.eye(N) + delta/2 * A)\n",
    "    Bbar = Bl@(delta*B)\n",
    "    return Abar, Bbar, Cbar, Dbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3305b7a1-5b3e-4abc-8d77-f34f8a399075",
   "metadata": {},
   "outputs": [],
   "source": [
    "Abar, Bbar, Cbar, Dbar = discretize(A, B, C, D, delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d72635d9-919f-4482-a03c-c6a364503b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 100\n",
    "num_steps = int(T/delta)\n",
    "\n",
    "u = torch.cos(torch.arange(num_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3134525-8e1e-40be-b02b-346dcbb7bb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scan_SSM(\n",
    "    Ab : torch.Tensor, Bb : torch.Tensor, Cb : torch.Tensor, Db : torch.Tensor,  u : torch.Tensor, x0 : torch.Tensor\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    computes steps of the SSM going forward.\n",
    "\n",
    "    parameters:\n",
    "        Ab : (NxN) transition matrix in discrete space of latent to latent\n",
    "        Bb : (Nx1) projcetion matrix from input to latent space\n",
    "        Cb : (1xN) projection matrix from latent to output\n",
    "        Db : (1x1) skip connection input to output\n",
    "        u  : (L,)  trajectory we are trying to track\n",
    "        x0 : (Nx1) initial condition of latent\n",
    "    \"\"\"\n",
    "    x0 = torch.zeros((10,1))\n",
    "    x = torch.zeros((Ab.shape[0], len(u[:100])))\n",
    "    y = torch.zeros_like(u[:100])\n",
    "    for i in range(u[:100].shape[0]):\n",
    "        x[:,i] = (Ab@x0 + Bb*u[i]).squeeze()\n",
    "        y[i] = (Cb@x[:,i]).squeeze()\n",
    "        x0 = x[:,i].unsqueeze(-1)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "397018e5-477a-4464-875d-00e7156dcc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def K_conv(Ab : torch.Tensor, Bb : torch.Tensor, Cb : torch.Tensor, L : int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    computes convolution window given L time steps using equation K_t = Cb @ (Ab^t) @ Bb. \n",
    "    Needs to be flipped for correct causal convolution, but can be used as is in fft mode\n",
    "\n",
    "    parameters:\n",
    "        Ab : transition matrix\n",
    "        Bb : projection matrix from input to latent\n",
    "        Cb : projection matrix from latent to input\n",
    "        Db : skip connection\n",
    "        L  : length over which we want convolutional window\n",
    "    \"\"\"\n",
    "    return torch.stack([(Cb @ torch.matrix_power(Ab, l) @ Bb).squeeze() for l in range(L)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4daebfc-d2d8-41b9-8599-4ddd690b3485",
   "metadata": {},
   "outputs": [],
   "source": [
    "def causal_conv(u : torch.Tensor, K : torch.Tensor, notfft : bool = False) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    computes 1-d causal convolution either using standard method or fft transform.\n",
    "\n",
    "    parameters:\n",
    "        u : trajectory to convolve\n",
    "        K : convolutional filter\n",
    "        notfft: boolean, for whether or not we use fft mode or not.\n",
    "    \"\"\"\n",
    "    assert len(u.shape)==1\n",
    "    assert K.shape==u.shape\n",
    "    \n",
    "    L = u.shape[0]\n",
    "    powers_of_2 = 2**int(math.ceil(math.log2(2*L)))\n",
    "\n",
    "    if notfft:\n",
    "        padded_u = torch.nn.functional.pad(u, (L-1,L-1))\n",
    "        convolve = torch.zeros_like(u)\n",
    "        for i in range(L):\n",
    "            convolve[i] = torch.sum(padded_u[i:i+L]*K.flip(dims=[0]))\n",
    "        return convolve\n",
    "    else:\n",
    "\n",
    "        K_pad = torch.nn.functional.pad(K, (0, L))\n",
    "        u_pad = torch.nn.functional.pad(u, (0, L))\n",
    "        \n",
    "        K_f, u_f = torch.fft.rfft(K_pad, n = powers_of_2), torch.fft.rfft(u_pad, n = powers_of_2)\n",
    "        return torch.fft.irfft(K_f * u_f, n = powers_of_2)[:L]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0d3efcc-e3f7-43ca-bda3-7601774fd727",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = K_conv(Abar, Bbar, Cbar, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f74b795-1716-45f9-8c7e-3be76d1a88e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_fft = causal_conv(u[:100], K)\n",
    "conv_notfft = causal_conv(u[:100],K , notfft=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f4895f0-52c5-444c-9837-f90d033de1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = scan_SSM(Abar, Bbar, Cbar, Dbar, u[:100], torch.zeros((10,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "baa14979-dfe1-41e2-b0ae-9834511822a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(True)\n",
      "tensor(True)\n"
     ]
    }
   ],
   "source": [
    "print((abs(conv_fft - conv_notfft)<1e-5).all())\n",
    "print((abs(conv_fft - y)<1e-5).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad8c56ba-ea9b-4ed5-bb0a-82539bd529b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_step_initializer(dt_min = 0.001, dt_max = 0.1):\n",
    "    \"\"\"\n",
    "    initial guess for dt, from random number generator. to be learned.\n",
    "\n",
    "    parameters:\n",
    "        dt_min\n",
    "        dt_max\n",
    "    \"\"\"\n",
    "    return torch.autograd.Variable(torch.rand(1) * (torch.log(dt_max) - torch.log(dt_min)) + torch.log(dt_min), requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47782377-fad9-4f35-a7c5-4c12a7ffbdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SSMLayer(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Simple layer that does SSMing. Assumes single input, single output. \n",
    "    Could be made multi-dimensional either by stacking and decorrelating,\n",
    "    or by playing with the code to allow for multi input, multioutput. Should be relatively easy, \n",
    "    but need to carefully think a little about convolution of multi dim inputs.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        latent_dim,\n",
    "        L_max,\n",
    "        dt_min = 0.001,\n",
    "        dt_max = 0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.A, self.B, self.C, self.D = self.random_SSM(latent_dim)\n",
    "        self.Abar, self.Bbar, self.Cbar, self.Dbar = self.discretize(self.A, self.B, self.C, self.D, self.dt)\n",
    "        self.dt = self.log_step_initializer(dt_min, dt_max)\n",
    "\n",
    "    def random_SSM(\n",
    "        self, \n",
    "        N : int\n",
    "    ) -> (torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor):\n",
    "        \"\"\"\n",
    "        initializing SSM parameters given latent dim\n",
    "        \n",
    "        parameters:\n",
    "            N : size of latent dimension\n",
    "        \"\"\"\n",
    "        A = torch.autograd.Variable(torch.rand(size=(N,N)), requires_grad = True)\n",
    "        B = torch.autograd.Variable(torch.rand(size=(N,1)), requires_grad = True)\n",
    "        C = torch.autograd.Variable(torch.rand(size=(1,N)), requires_grad = True)\n",
    "        D = torch.autograd.Variable(torch.rand(size=(1,1)), requires_grad = True)\n",
    "        return A, B, C, D\n",
    "\n",
    "    def log_step_initializer(self, dt_min = 0.001, dt_max = 0.1):\n",
    "        \"\"\"\n",
    "        initial guess for dt, from random number generator. to be learned.\n",
    "    \n",
    "        parameters:\n",
    "            dt_min\n",
    "            dt_max\n",
    "        \"\"\"\n",
    "        return torch.autograd.Variable(torch.rand(1) * (torch.log(dt_max) - torch.log(dt_min)) + torch.log(dt_min), requires_grad = True)\n",
    "\n",
    "    def discretize(\n",
    "        self, A : torch.Tensor, B : torch.Tensor, C : torch.Tensor, D : torch.Tensor, delta : torch.Tensor\n",
    "    ) -> (torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor):\n",
    "        \"\"\"Discretizes SSM using bilinear model\n",
    "    \n",
    "        parameters:\n",
    "            A: (NxN) transition matrix in latent\n",
    "            B: (Nx1) projection matrix to latent\n",
    "            C: (1xN) projection matrix from latent to output\n",
    "            D: (1x1) skip connection from input to output\n",
    "            delta: time step, ensure sufficient smallness\n",
    "        \"\"\"\n",
    "        Cbar = C\n",
    "        Dbar = D\n",
    "        N = A.shape[0]\n",
    "        Bl = torch.linalg.inv(torch.eye(N) - delta / 2 * A)\n",
    "        Abar = Bl@(torch.eye(N) + delta/2 * A)\n",
    "        Bbar = Bl@(delta*B)\n",
    "        return Abar, Bbar, Cbar, Dbar\n",
    "\n",
    "    def scan_SSM(\n",
    "        self, Ab : torch.Tensor, Bb : torch.Tensor, Cb : torch.Tensor, Db : torch.Tensor,  u : torch.Tensor, x0 : torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        computes steps of the SSM going forward.\n",
    "    \n",
    "        parameters:\n",
    "            Ab : (NxN) transition matrix in discrete space of latent to latent\n",
    "            Bb : (Nx1) projcetion matrix from input to latent space\n",
    "            Cb : (1xN) projection matrix from latent to output\n",
    "            Db : (1x1) skip connection input to output\n",
    "            u  : (L,)  trajectory we are trying to track\n",
    "            x0 : (Nx1) initial condition of latent\n",
    "        \"\"\"\n",
    "        x0 = torch.zeros((10,1))\n",
    "        x = torch.zeros((Ab.shape[0], len(u[:100])))\n",
    "        y = torch.zeros_like(u[:100])\n",
    "        for i in range(u[:100].shape[0]):\n",
    "            x[:,i] = (Ab@x0 + Bb*u[i]).squeeze()\n",
    "            y[i] = (Cb@x[:,i]).squeeze()\n",
    "            x0 = x[:,i].unsqueeze(-1)\n",
    "        return x, y\n",
    "        \n",
    "    def K_conv(self, Ab : torch.Tensor, Bb : torch.Tensor, Cb : torch.Tensor, L : int) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        computes convolution window given L time steps using equation K_t = Cb @ (Ab^t) @ Bb. \n",
    "        Needs to be flipped for correct causal convolution, but can be used as is in fft mode\n",
    "    \n",
    "        parameters:\n",
    "            Ab : transition matrix\n",
    "            Bb : projection matrix from input to latent\n",
    "            Cb : projection matrix from latent to input\n",
    "            Db : skip connection\n",
    "            L  : length over which we want convolutional window\n",
    "        \"\"\"\n",
    "        return torch.stack([(Cb @ torch.matrix_power(Ab, l) @ Bb).squeeze() for l in range(L)])\n",
    "\n",
    "    def causal_conv(u : torch.Tensor, K : torch.Tensor, notfft : bool = False) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        computes 1-d causal convolution either using standard method or fft transform.\n",
    "    \n",
    "        parameters:\n",
    "            u : trajectory to convolve\n",
    "            K : convolutional filter\n",
    "            notfft: boolean, for whether or not we use fft mode or not.\n",
    "        \"\"\"\n",
    "        assert K.shape==u.shape\n",
    "        \n",
    "        L = u.shape[0]\n",
    "        powers_of_2 = 2**int(math.ceil(math.log2(2*L)))\n",
    "    \n",
    "        if notfft:\n",
    "            padded_u = torch.nn.functional.pad(u, (L-1,L-1))\n",
    "            convolve = torch.zeros_like(u)\n",
    "            for i in range(L):\n",
    "                convolve[i] = torch.sum(padded_u[i:i+L]*K.flip(dims=[0]))\n",
    "            return convolve\n",
    "        else:\n",
    "    \n",
    "            K_pad = torch.nn.functional.pad(K, (0, L))\n",
    "            u_pad = torch.nn.functional.pad(u, (0, L))\n",
    "            \n",
    "            K_f, u_f = torch.fft.rfft(K_pad, n = powers_of_2), torch.fft.rfft(u_pad, n = powers_of_2)\n",
    "            return torch.fft.irfft(K_f * u_f, n = powers_of_2)[:L]\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        u : torch.Tensor,\n",
    "        x0 : torch.Tensor = torch.zeros((1,1)),\n",
    "        mode : bool | str = False\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        forward pass of model\n",
    "\n",
    "        Parameters:\n",
    "            u  : input time series\n",
    "            x0 : initial condition, only used in recurrent mode\n",
    "            mode: recurrent mode (\"recurrent\"), or convolution mode (True : direct convolution, False : fourier transform)\n",
    "        \"\"\"\n",
    "        if mode == \"recurrent\":\n",
    "            return self.scan_SSM(self.Abar, self.Bbar, self.Cbar, u, x0)[1]\n",
    "        else:\n",
    "            K = self.K_conv(self.Abar, self.Bbar, self.Cbar, u.shape[0])\n",
    "            return self.causal_conv(u, K, mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5306197b-fa32-44f1-a7b3-6a2c61c0675d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_HiPPO(N : int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    creates HiPPO matrix for legendre polynomials up to order N\n",
    "    parameters:\n",
    "        N: int\n",
    "    \"\"\"\n",
    "    P = torch.sqrt(1+2*torch.arange(N))\n",
    "    A = P.unsqueeze(1) * P.unsqueeze(0)\n",
    "    A = torch.tril(A) - torch.diag(torch.arange(N))\n",
    "    return -A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "71aa99a8-a247-4d94-b7c3-93ac93bbbf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def K_gen_inverse(\n",
    "    Abar : torch.Tensor, Bbar : torch.Tensor, Cbar : torch.Tensor, L : int\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    creates generating function for convolutional window, to be evaluated at roots of unity\n",
    "    parameters:\n",
    "        Abar : discretized A matrix\n",
    "        Bbar : discretized B matrix\n",
    "        Cbar : discretized C matrix\n",
    "        L    : length of convolutional window\n",
    "    \"\"\"\n",
    "    Abar = Abar.to(torch.complex64)\n",
    "    Bbar = Bbar.to(torch.complex64)\n",
    "    Cbar = Cbar.to(torch.complex64)\n",
    "    \n",
    "    I = torch.eye(Abar.shape[0]).to(torch.complex64)\n",
    "    Al = torch.matrix_power(Abar, L)\n",
    "    Ctilde = Cbar @ (I - (Al))\n",
    "    return lambda z: (torch.conj(Ctilde)@(torch.linalg.inv(I-(Abar * z)))@Bbar).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ddce6900-8991-4cf9-ac63-9b2159051b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_from_gen(gen : Callable, L : int):\n",
    "    \"\"\"\n",
    "    returns convolution from generating function by evaluating at roots of unity\n",
    "\n",
    "    parameters:\n",
    "        gen : generating function\n",
    "        L   : int\n",
    "    \"\"\"\n",
    "    omega_L = torch.exp(-2j * torch.pi * torch.arange(L)/L)\n",
    "    atRoots = torch.tensor([gen(omega) for omega in omega_L])\n",
    "    return torch.fft.irfft(atRoots, L).squeeze()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e4606f8b-22a8-479b-abbf-0ef619b4e716",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cauchy(v : torch.Tensor, omega : torch.Tensor, lambd : torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    helper function for calculating cauchy kernel in generating function\n",
    "\n",
    "    parameters:\n",
    "        v : a dot product vector, relying on DPLR representation of SSM matrices\n",
    "        omega : complex poles\n",
    "        lambd : diagonal values of A matrix stand-in\n",
    "    \"\"\"\n",
    "    cauchy_dot = lambda _omega: (v/(omega-lamb)).sum()\n",
    "    return cauchy_dot\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "20fe8246-72ca-480e-9144-81e079776339",
   "metadata": {},
   "outputs": [],
   "source": [
    "def K_gen_DPLR(\n",
    "    Lambda : torch.Tensor, \n",
    "    P : torch.Tensor, \n",
    "    Q : torch.Tensor, \n",
    "    B: torch.Tensor, \n",
    "    C : torch.Tensor, \n",
    "    delta : torch.Tensor, \n",
    "    L : int\n",
    ")-> torch.Tensor:\n",
    "    \"\"\"\n",
    "    computes convolution kernel from generating function using DPLR representation and\n",
    "    the cauchy kernel\n",
    "\n",
    "    Parameters:\n",
    "        Lambda : diagonal part of A\n",
    "        P : Nx1 matrix, rank 1 representation to A\n",
    "        Q : Nx1 matrix, rank 1 representation to A\n",
    "        C : 1xN matrix, projection from latent to input\n",
    "        B : Nx1 matrix, projection from input to latent\n",
    "    \"\"\"\n",
    "    Omega_L = torch.exp(-2j*torch.pi * (torch.arange(L))/L)\n",
    "\n",
    "    aterm = (torch.conj(C), torch.conj(Q))\n",
    "    bterm = (B, P)\n",
    "\n",
    "    g = (2.0/delta) * ((1.0-Omega_L)/(1.0+Omega_L))\n",
    "    c = 2.0 / (1.0+Omega_L)\n",
    "\n",
    "    k00 = cauchy(aterm[0] * bterm[0], g, Lambda)\n",
    "    k01 = cauchy(aterm[0] * bterm[1], g, Lambda)\n",
    "    k10 = cauchy(aterm[1] * bterm[0], g, Lambda)\n",
    "    k11 = cauchy(aterm[1] * bterm[1], g, Lambda)\n",
    "\n",
    "    atRoots = c * (k00 - k01 * (1.0 / (1.0 + k11)) * k10)\n",
    "    out = np.fft.irfft(atRoots, L)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f56321fc-5778-4b35-931a-0ff229106b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discrete_DPLR(\n",
    "    Lambda : torch.Tensor,\n",
    "    P : torch.Tensor,\n",
    "    Q : torch.Tensor,\n",
    "    B : torch.Tensor,\n",
    "    C : torch.Tensor,\n",
    "    delta : torch.Tensor,\n",
    "    L : int\n",
    ")->(torch.Tensor, torch.Tensor, torch.Tensor):\n",
    "    \"\"\"\n",
    "    computes the discretized version of the state space model,\n",
    "    assuming the DPLR form\n",
    "\n",
    "    Parameters:\n",
    "        Lambda : Nx1, represents the diagonal values of the A matrix\n",
    "        P : Nx1, represents part of the low rank aspect of the A matrix\n",
    "        Q : Nx1, represents the other part of the low rank aspect of the A matrix\n",
    "        B : N, projection from input to latent\n",
    "        C : N, projection from latent to input\n",
    "        delta : step size\n",
    "        L : length of window\n",
    "    \"\"\"\n",
    "    Bt = B.unsqueeze(1)\n",
    "    Ct = C.unsqueeze(0)\n",
    "\n",
    "    A = (torch.diag(Lambda) - torch.outer(P, torch.conj(Q)))\n",
    "    A0 = 2.0/delta * torch.eye(A.shape[0]) + A\n",
    "\n",
    "    Qdagger = torch.conj(torch.transpose(Q))\n",
    "    \n",
    "    D = torch.diag(1.0/(2.0/delta - Lambda))\n",
    "    A1 = (D -  (1.0/(1.0 + Qdagger @ D @ P)) * D@P@Qdagger@D)\n",
    "    Ab = A1@A0\n",
    "    Bb = 2 * A1\n",
    "    Cb = Ct @ torch.conj(torch.linalg.inv(torch.eye(A.shape[0]) - torch.matrix_power(Ab, L)))\n",
    "    return Ab, Bb, Cb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "36b778f2-3e39-4bd6-821a-032e7f0c3436",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_NPLR_HiPPO(N : int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    creating hippo matrix and associated low rank additive component, P\n",
    "    and the B matrix associated, as hippo forces it\n",
    "\n",
    "    parameters:\n",
    "        N : int, degree of legendre polynomial coefficient\n",
    "    \"\"\"\n",
    "    nhippo = make_HiPPO(N)\n",
    "\n",
    "    P = torch.sqrt(torch.arange(N)+0.5).to(torch.complex64)\n",
    "    B = torch.sqrt(2*torch.arange(N)+1.0).to(torch.complex64)\n",
    "\n",
    "    return nhippo.to(torch.complex64), P, B\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a5c323dd-ae2a-4a55-b903-b0d347e15699",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_DPLR_HiPPO(N : int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    convert matrices to DPLR representation\n",
    "    parameters:\n",
    "        N : int, degree of legendre polynomials\n",
    "    \"\"\"\n",
    "    A, P, B = make_NPLR_HiPPO(N)\n",
    "\n",
    "    S = A + torch.outer(P, P)\n",
    "\n",
    "    S_diag = torch.diagonal(S)\n",
    "    Lambda_real = torch.mean(S_diag) * torch.ones_like(S_diag)\n",
    "\n",
    "    Lambda_imag, V = torch.linalg.eigh(S * -1j)\n",
    "    P = V.T.conj() @ P\n",
    "    B = V.T.conj() @ B\n",
    "    return Lambda_real + 1j * Lambda_imag, P, B, V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f7e5519a-b02a-43d6-9700-4c5377371354",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ -1.0000+0.j,  -0.0000+0.j,  -0.0000+0.j,  -0.0000+0.j,  -0.0000+0.j,  -0.0000+0.j,\n",
      "          -0.0000+0.j,  -0.0000+0.j],\n",
      "        [ -1.7321+0.j,  -2.0000+0.j,  -0.0000+0.j,  -0.0000+0.j,  -0.0000+0.j,  -0.0000+0.j,\n",
      "          -0.0000+0.j,  -0.0000+0.j],\n",
      "        [ -2.2361+0.j,  -3.8730+0.j,  -3.0000+0.j,  -0.0000+0.j,  -0.0000+0.j,  -0.0000+0.j,\n",
      "          -0.0000+0.j,  -0.0000+0.j],\n",
      "        [ -2.6458+0.j,  -4.5826+0.j,  -5.9161+0.j,  -4.0000+0.j,  -0.0000+0.j,  -0.0000+0.j,\n",
      "          -0.0000+0.j,  -0.0000+0.j],\n",
      "        [ -3.0000+0.j,  -5.1962+0.j,  -6.7082+0.j,  -7.9373+0.j,  -5.0000+0.j,  -0.0000+0.j,\n",
      "          -0.0000+0.j,  -0.0000+0.j],\n",
      "        [ -3.3166+0.j,  -5.7446+0.j,  -7.4162+0.j,  -8.7750+0.j,  -9.9499+0.j,  -6.0000+0.j,\n",
      "          -0.0000+0.j,  -0.0000+0.j],\n",
      "        [ -3.6056+0.j,  -6.2450+0.j,  -8.0623+0.j,  -9.5394+0.j, -10.8167+0.j, -11.9583+0.j,\n",
      "          -7.0000+0.j,  -0.0000+0.j],\n",
      "        [ -3.8730+0.j,  -6.7082+0.j,  -8.6603+0.j, -10.2470+0.j, -11.6189+0.j, -12.8452+0.j,\n",
      "         -13.9642+0.j,  -8.0000+0.j]])\n",
      "tensor([[-1.0000e+00-6.9707e-08j, -2.9802e-07+2.8418e-09j,\n",
      "         -3.5763e-07+6.2434e-07j, -3.5763e-07+5.9046e-07j,\n",
      "         -1.1921e-06+6.1039e-07j, -2.0266e-06+1.4021e-07j,\n",
      "         -1.6689e-06-8.8670e-07j, -5.9605e-07-5.7045e-07j],\n",
      "        [-1.7321e+00-7.8643e-08j, -2.0000e+00+2.6949e-06j,\n",
      "          4.7684e-07+1.3714e-06j,  2.3842e-07+1.7700e-06j,\n",
      "         -1.1921e-06+1.1226e-06j, -1.9073e-06+2.0191e-07j,\n",
      "         -2.1458e-06-1.1681e-06j, -2.3842e-07-3.0963e-06j],\n",
      "        [-2.2361e+00+6.0187e-07j, -3.8730e+00+1.2433e-06j,\n",
      "         -3.0000e+00+2.0096e-06j, -4.7684e-07+7.7750e-07j,\n",
      "          2.3842e-07+9.3768e-07j, -1.9073e-06-5.8219e-07j,\n",
      "         -2.3842e-06-1.1572e-06j, -1.4305e-06-2.5735e-06j],\n",
      "        [-2.6458e+00+7.2498e-07j, -4.5826e+00+1.5742e-06j,\n",
      "         -5.9161e+00+7.3081e-07j, -4.0000e+00+2.6595e-07j,\n",
      "          0.0000e+00+5.5198e-07j, -2.3842e-06-1.7120e-07j,\n",
      "         -3.8147e-06-6.4483e-07j, -1.9073e-06-1.7348e-06j],\n",
      "        [-3.0000e+00+5.4658e-07j, -5.1962e+00+8.9640e-07j,\n",
      "         -6.7082e+00+9.3953e-07j, -7.9373e+00+4.7708e-07j,\n",
      "         -5.0000e+00+4.1160e-07j, -4.7684e-07+1.1251e-07j,\n",
      "         -2.8610e-06-8.2578e-07j, -2.8610e-06-2.1931e-06j],\n",
      "        [-3.3166e+00+1.3621e-07j, -5.7446e+00-1.7300e-08j,\n",
      "         -7.4162e+00-6.6709e-07j, -8.7750e+00-1.9479e-07j,\n",
      "         -9.9499e+00-3.8170e-07j, -6.0000e+00-5.4159e-08j,\n",
      "         -2.8610e-06-6.7491e-07j, -3.8147e-06-6.4431e-07j],\n",
      "        [-3.6055e+00-7.9544e-07j, -6.2450e+00-1.1184e-06j,\n",
      "         -8.0623e+00-1.5209e-06j, -9.5394e+00-8.0545e-07j,\n",
      "         -1.0817e+01-8.5218e-07j, -1.1958e+01-5.8182e-07j,\n",
      "         -7.0000e+00+6.0483e-07j, -2.8610e-06+1.2083e-06j],\n",
      "        [-3.8730e+00-3.9634e-07j, -6.7082e+00-2.8920e-06j,\n",
      "         -8.6603e+00-2.3747e-06j, -1.0247e+01-1.3913e-06j,\n",
      "         -1.1619e+01-2.3939e-06j, -1.2845e+01-5.5860e-07j,\n",
      "         -1.3964e+01+9.4411e-07j, -8.0000e+00+2.2398e-06j]])\n",
      "tensor([[-1.0000e+00-8.7178e-08j, -2.2839e-07-8.5697e-07j,\n",
      "          9.8230e-08-8.6038e-08j, -6.9196e-08-2.3358e-07j,\n",
      "         -2.1919e-07-3.8054e-07j, -7.0612e-07-4.7662e-07j,\n",
      "         -6.3689e-07-1.3371e-06j,  2.2188e-07-1.5176e-06j],\n",
      "        [-1.7321e+00+7.6665e-07j, -2.0000e+00+2.9973e-06j,\n",
      "         -1.4901e-07+2.1716e-06j, -6.7055e-07+2.3961e-06j,\n",
      "         -1.3262e-06+1.6971e-06j, -1.5497e-06+1.6963e-06j,\n",
      "         -2.0266e-06+5.9360e-07j, -6.5565e-07-2.1703e-06j],\n",
      "        [-2.2361e+00+1.1017e-06j, -3.8730e+00+5.1762e-07j,\n",
      "         -3.0000e+00+1.6319e-06j, -2.6822e-07+2.0490e-07j,\n",
      "          1.9073e-06+3.3562e-07j,  4.8429e-07-3.5193e-07j,\n",
      "         -1.3113e-06-1.7883e-07j, -1.1921e-06-2.4973e-06j],\n",
      "        [-2.6458e+00+1.5090e-06j, -4.5826e+00+1.1279e-06j,\n",
      "         -5.9161e+00+1.2001e-06j, -4.0000e+00+2.7232e-07j,\n",
      "          8.7917e-07+3.7385e-07j, -7.1526e-07+1.0229e-06j,\n",
      "         -3.3975e-06+1.3944e-06j, -1.9073e-06-5.7846e-07j],\n",
      "        [-3.0000e+00+1.6807e-06j, -5.1962e+00+3.7875e-07j,\n",
      "         -6.7082e+00+1.6589e-06j, -7.9373e+00+7.0677e-07j,\n",
      "         -5.0000e+00+2.8709e-07j,  3.4645e-06+1.1486e-06j,\n",
      "         -4.7684e-07+1.2883e-06j, -1.9073e-06-9.4076e-07j],\n",
      "        [-3.3166e+00+6.6667e-07j, -5.7446e+00-1.6813e-06j,\n",
      "         -7.4162e+00-7.6428e-07j, -8.7750e+00-1.2126e-06j,\n",
      "         -9.9499e+00-1.3512e-06j, -6.0000e+00-1.7152e-07j,\n",
      "          1.9073e-06-1.3473e-07j, -9.5367e-07-9.5030e-07j],\n",
      "        [-3.6055e+00-1.8072e-07j, -6.2450e+00-2.7298e-06j,\n",
      "         -8.0623e+00-1.5354e-06j, -9.5394e+00-2.3110e-06j,\n",
      "         -1.0817e+01-2.2328e-06j, -1.1958e+01-1.3892e-06j,\n",
      "         -7.0000e+00+7.6600e-07j, -1.4305e-06-1.2377e-06j],\n",
      "        [-3.8730e+00+2.0859e-07j, -6.7082e+00-4.8941e-06j,\n",
      "         -8.6603e+00-2.5812e-06j, -1.0247e+01-1.9016e-06j,\n",
      "         -1.1619e+01-3.5476e-06j, -1.2845e+01-2.4379e-08j,\n",
      "         -1.3964e+01+2.2724e-06j, -8.0000e+00+3.1667e-06j]])\n"
     ]
    }
   ],
   "source": [
    "N=8\n",
    "A2, P, B = make_NPLR_HiPPO(N)\n",
    "Lambda, Pc, Bc, V = make_DPLR_HiPPO(N)\n",
    "Vc = V.conj().T\n",
    "P = P\n",
    "Pc = Pc\n",
    "Lambda = torch.diag(Lambda)\n",
    "A3 = V @ Lambda @ Vc - torch.outer(P,P.conj())  # Test NPLR\n",
    "A4 = V @ (Lambda - torch.outer(Pc,Pc.conj())) @ Vc  # Test DPLR\n",
    "print(A2)\n",
    "print(A3)\n",
    "print(A4)\n",
    "assert torch.allclose(A2, A3, atol=1e-4, rtol=1e-4)\n",
    "assert torch.allclose(A2, A4, atol=1e-4, rtol=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7e31089d-5abb-4d09-938f-95e2b5a8cd93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -1.0000+0.j,  -0.0000+0.j,  -0.0000+0.j,  -0.0000+0.j,  -0.0000+0.j,  -0.0000+0.j,\n",
       "          -0.0000+0.j,  -0.0000+0.j],\n",
       "        [ -1.7321+0.j,  -2.0000+0.j,  -0.0000+0.j,  -0.0000+0.j,  -0.0000+0.j,  -0.0000+0.j,\n",
       "          -0.0000+0.j,  -0.0000+0.j],\n",
       "        [ -2.2361+0.j,  -3.8730+0.j,  -3.0000+0.j,  -0.0000+0.j,  -0.0000+0.j,  -0.0000+0.j,\n",
       "          -0.0000+0.j,  -0.0000+0.j],\n",
       "        [ -2.6458+0.j,  -4.5826+0.j,  -5.9161+0.j,  -4.0000+0.j,  -0.0000+0.j,  -0.0000+0.j,\n",
       "          -0.0000+0.j,  -0.0000+0.j],\n",
       "        [ -3.0000+0.j,  -5.1962+0.j,  -6.7082+0.j,  -7.9373+0.j,  -5.0000+0.j,  -0.0000+0.j,\n",
       "          -0.0000+0.j,  -0.0000+0.j],\n",
       "        [ -3.3166+0.j,  -5.7446+0.j,  -7.4162+0.j,  -8.7750+0.j,  -9.9499+0.j,  -6.0000+0.j,\n",
       "          -0.0000+0.j,  -0.0000+0.j],\n",
       "        [ -3.6056+0.j,  -6.2450+0.j,  -8.0623+0.j,  -9.5394+0.j, -10.8167+0.j, -11.9583+0.j,\n",
       "          -7.0000+0.j,  -0.0000+0.j],\n",
       "        [ -3.8730+0.j,  -6.7082+0.j,  -8.6603+0.j, -10.2470+0.j, -11.6189+0.j, -12.8452+0.j,\n",
       "         -13.9642+0.j,  -8.0000+0.j]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "02fccb0e-303e-4d4c-ad3d-619157678671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ -3.8730-3.9634e-07j,  -6.7082-2.8920e-06j,  -8.6603-2.3747e-06j,\n",
       "        -10.2470-1.3913e-06j, -11.6189-2.3939e-06j, -12.8452-5.5860e-07j,\n",
       "        -13.9642+9.4411e-07j,  -8.0000+2.2398e-06j])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A3[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "69909947-bf66-434a-9083-32e0c09a0ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.0000+0.j,  0.0000+0.j,  0.0000+0.j,  0.0000+0.j,  0.0000+0.j,  0.0000+0.j,\n",
      "          0.0000+0.j,  0.0000+0.j],\n",
      "        [ 1.7321+0.j,  2.0000+0.j,  0.0000+0.j,  0.0000+0.j,  0.0000+0.j,  0.0000+0.j,\n",
      "          0.0000+0.j,  0.0000+0.j],\n",
      "        [ 2.2361+0.j,  3.8730+0.j,  3.0000+0.j,  0.0000+0.j,  0.0000+0.j,  0.0000+0.j,\n",
      "          0.0000+0.j,  0.0000+0.j],\n",
      "        [ 2.6458+0.j,  4.5826+0.j,  5.9161+0.j,  4.0000+0.j,  0.0000+0.j,  0.0000+0.j,\n",
      "          0.0000+0.j,  0.0000+0.j],\n",
      "        [ 3.0000+0.j,  5.1962+0.j,  6.7082+0.j,  7.9373+0.j,  5.0000+0.j,  0.0000+0.j,\n",
      "          0.0000+0.j,  0.0000+0.j],\n",
      "        [ 3.3166+0.j,  5.7446+0.j,  7.4162+0.j,  8.7750+0.j,  9.9499+0.j,  6.0000+0.j,\n",
      "          0.0000+0.j,  0.0000+0.j],\n",
      "        [ 3.6056+0.j,  6.2450+0.j,  8.0623+0.j,  9.5394+0.j, 10.8167+0.j, 11.9583+0.j,\n",
      "          7.0000+0.j,  0.0000+0.j],\n",
      "        [ 3.8730+0.j,  6.7082+0.j,  8.6603+0.j, 10.2470+0.j, 11.6189+0.j, 12.8452+0.j,\n",
      "         13.9642+0.j,  8.0000+0.j]])\n",
      "tensor([[  8.0000-1.7481e-07j,  -3.4641+1.7865e-06j,  -4.4721+5.4055e-07j,\n",
      "          -5.2915+1.1589e-06j,  -6.0000-4.1068e-08j,  -6.6332-5.2920e-07j,\n",
      "          -7.2111-4.2458e-07j,  -7.7460-1.5075e-06j],\n",
      "        [  1.7320+7.2528e-07j,   7.0000+8.9843e-07j,  -7.7460+3.0831e-06j,\n",
      "          -9.1652+4.1855e-06j, -10.3923-1.4810e-06j, -11.4891-2.2611e-06j,\n",
      "         -12.4900-1.4474e-06j, -13.4164-2.6784e-06j],\n",
      "        [  2.2361+9.3382e-07j,   3.8730+2.5823e-06j,   6.0000+4.9254e-06j,\n",
      "         -11.8322+4.3769e-06j, -13.4164+1.4062e-06j, -14.8324-5.2895e-06j,\n",
      "         -16.1245+2.3412e-07j, -17.3205+1.2076e-06j],\n",
      "        [  2.6458+8.0854e-07j,   4.5826+2.8183e-06j,   5.9161+2.0063e-06j,\n",
      "           5.0000+6.3422e-06j, -15.8745+2.5605e-06j, -17.5499-1.7270e-06j,\n",
      "         -19.0788-2.7953e-06j, -20.4939+4.7497e-07j],\n",
      "        [  3.0000+8.9942e-07j,   5.1962-2.3873e-06j,   6.7082+8.2643e-07j,\n",
      "           7.9373+1.0366e-08j,   4.0000+5.4192e-07j, -19.8997-2.6274e-06j,\n",
      "         -21.6333-5.4430e-06j, -23.2379-4.7275e-06j],\n",
      "        [  3.3166+6.1739e-07j,   5.7446+8.9926e-07j,   7.4162-1.5770e-06j,\n",
      "           8.7750-1.0905e-06j,   9.9499-6.4100e-06j,   3.0000-6.5835e-06j,\n",
      "         -23.9165-1.0338e-06j, -25.6905-4.7906e-06j],\n",
      "        [  3.6056+2.5862e-07j,   6.2450-3.0317e-06j,   8.0623+2.8046e-06j,\n",
      "           9.5394-3.1874e-07j,  10.8167-7.1586e-06j,  11.9583-3.9815e-06j,\n",
      "           2.0000+2.4461e-06j, -27.9285+6.2509e-07j],\n",
      "        [  3.8730-1.3957e-06j,   6.7082-4.7963e-06j,   8.6602-2.5347e-06j,\n",
      "          10.2470-1.9525e-06j,  11.6189-2.2388e-06j,  12.8452-3.5802e-06j,\n",
      "          13.9642+1.2984e-07j,   1.0000+5.5498e-06j]])\n",
      "tensor([[  8.0000-2.0094e-07j,  -3.4641+1.8109e-06j,  -4.4721+5.1827e-07j,\n",
      "          -5.2915+1.5164e-06j,  -6.0000+1.6214e-07j,  -6.6332-1.4762e-07j,\n",
      "          -7.2111-3.1748e-07j,  -7.7460-2.2092e-07j],\n",
      "        [  1.7321+3.8124e-07j,   7.0000-1.3208e-07j,  -7.7460+2.6664e-06j,\n",
      "          -9.1652+3.7574e-06j, -10.3923-1.8508e-06j, -11.4891-2.4029e-06j,\n",
      "         -12.4900-2.4457e-06j, -13.4164-2.9898e-06j],\n",
      "        [  2.2361+7.2410e-07j,   3.8730+1.4908e-06j,   6.0000+4.1692e-06j,\n",
      "         -11.8322+3.8052e-06j, -13.4164+1.1438e-06j, -14.8324-5.0748e-06j,\n",
      "         -16.1245+8.0981e-07j, -17.3205+2.0406e-06j],\n",
      "        [  2.6458+3.3428e-07j,   4.5826+3.0292e-06j,   5.9161+2.1695e-06j,\n",
      "           5.0000+6.5565e-06j, -15.8745+1.9085e-06j, -17.5499-1.8702e-06j,\n",
      "         -19.0788-4.2094e-06j, -20.4939-1.5527e-06j],\n",
      "        [  3.0000+6.0085e-07j,   5.1962-2.3832e-06j,   6.7082+7.9749e-07j,\n",
      "           7.9373+7.4578e-07j,   4.0000+1.0209e-07j, -19.8997-2.4986e-06j,\n",
      "         -21.6333-7.0218e-06j, -23.2379-4.1664e-06j],\n",
      "        [  3.3166+2.0769e-07j,   5.7446+8.7039e-07j,   7.4162-1.9066e-06j,\n",
      "           8.7750-1.3280e-06j,   9.9499-6.5643e-06j,   3.0000-6.2480e-06j,\n",
      "         -23.9165-2.0243e-06j, -25.6905-5.2349e-06j],\n",
      "        [  3.6056-6.0197e-07j,   6.2450-3.0038e-06j,   8.0623+2.8911e-06j,\n",
      "           9.5394-8.7698e-08j,  10.8167-8.7280e-06j,  11.9583-4.4035e-06j,\n",
      "           2.0000+3.5006e-06j, -27.9285+1.5957e-06j],\n",
      "        [  3.8730-2.0744e-06j,   6.7082-3.2506e-06j,   8.6602-1.6386e-06j,\n",
      "          10.2470-9.4681e-07j,  11.6190-2.0097e-06j,  12.8452-2.5547e-06j,\n",
      "          13.9642-4.6403e-07j,   1.0000+4.4359e-06j]])\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[162], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtest_nplr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[161], line 13\u001b[0m, in \u001b[0;36mtest_nplr\u001b[0;34m(N)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(A3)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(A4)\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mallclose(A2, A3, atol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m, rtol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mallclose(A2, A4, atol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m, rtol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_nplr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "9f04eff4-3b0c-4852-8fa5-7961770cd07a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5818, 0.1010, 0.2738, 0.4646, 0.4686, 0.7683, 0.3008, 0.1447, 0.6443,\n",
       "         0.2300],\n",
       "        [0.4416, 0.3593, 0.4735, 0.5249, 0.9900, 0.6918, 0.0567, 0.2545, 0.0569,\n",
       "         0.0589],\n",
       "        [0.3173, 0.7228, 0.6870, 0.1064, 0.7708, 0.1748, 0.7994, 0.6445, 0.1681,\n",
       "         0.1523],\n",
       "        [0.0278, 0.0657, 0.8890, 0.6282, 0.3107, 0.5344, 0.8567, 0.9261, 0.9850,\n",
       "         0.0713],\n",
       "        [0.6945, 0.2748, 0.0964, 0.1249, 0.9149, 0.5747, 0.9080, 0.0049, 0.8492,\n",
       "         0.6751],\n",
       "        [0.7639, 0.7042, 0.0486, 0.5208, 0.3522, 0.8219, 0.8999, 0.0682, 0.4664,\n",
       "         0.5055],\n",
       "        [0.8660, 0.8240, 0.4073, 0.1050, 0.7550, 0.7808, 0.8962, 0.9453, 0.2059,\n",
       "         0.7177],\n",
       "        [0.7166, 0.1512, 0.7124, 0.8595, 0.1382, 0.5977, 0.2991, 0.1247, 0.4054,\n",
       "         0.5614],\n",
       "        [0.3957, 0.3469, 0.2057, 0.4245, 0.7076, 0.4653, 0.6787, 0.8338, 0.7559,\n",
       "         0.9425],\n",
       "        [0.8095, 0.1464, 0.8209, 0.0577, 0.9746, 0.0251, 0.8017, 0.7375, 0.7066,\n",
       "         0.1027]])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stuff.T.conj()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc29f66c-4ca6-43a4-9e1c-1d37798c5558",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
