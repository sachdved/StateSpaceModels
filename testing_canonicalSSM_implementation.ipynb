{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22af5475-eb30-47ca-b1dc-d85287a64f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "from collections.abc import Callable\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f37d9146-7137-4e38-a95f-01029f22a2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "\n",
    "class SSMLayer(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Simple layer that does SSMing. Assumes single input, single output. \n",
    "    Could be made multi-dimensional either by stacking and decorrelating,\n",
    "    or by playing with the code to allow for multi input, multioutput. Should be relatively easy, \n",
    "    but need to carefully think a little about convolution of multi dim inputs.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        latent_dim,\n",
    "        dt_min = torch.tensor(0.001),\n",
    "        dt_max = torch.tensor(0.1),\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.A, self.B, self.C, self.D = self.random_SSM(latent_dim)\n",
    "        self.dt = torch.exp(self.log_step_initializer(dt_min, dt_max))\n",
    "        self.Abar, self.Bbar, self.Cbar, self.Dbar = self.discretize(self.A, self.B, self.C, self.D, self.dt)\n",
    "\n",
    "\n",
    "    def random_SSM(\n",
    "        self, \n",
    "        N : int\n",
    "    ) -> (torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor):\n",
    "        \"\"\"\n",
    "        initializing SSM parameters given latent dim\n",
    "        \n",
    "        parameters:\n",
    "            N : size of latent dimension\n",
    "        \"\"\"\n",
    "        A = torch.autograd.Variable(torch.rand(size=(N,N)), requires_grad = True)\n",
    "        B = torch.autograd.Variable(torch.rand(size=(N,1)), requires_grad = True)\n",
    "        C = torch.autograd.Variable(torch.rand(size=(1,N)), requires_grad = True)\n",
    "        D = torch.autograd.Variable(torch.rand(size=(1,1)), requires_grad = True)\n",
    "        return A, B, C, D\n",
    "\n",
    "    def log_step_initializer(self, dt_min = 0.001, dt_max = 0.1):\n",
    "        \"\"\"\n",
    "        initial guess for dt, from random number generator. to be learned.\n",
    "    \n",
    "        parameters:\n",
    "            dt_min\n",
    "            dt_max\n",
    "        \"\"\"\n",
    "        return torch.autograd.Variable(torch.rand(1) * (torch.log(dt_max) - torch.log(dt_min)) + torch.log(dt_min), requires_grad = True)\n",
    "\n",
    "    def discretize(\n",
    "        self, A : torch.Tensor, B : torch.Tensor, C : torch.Tensor, D : torch.Tensor, delta : torch.Tensor\n",
    "    ) -> (torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor):\n",
    "        \"\"\"Discretizes SSM using bilinear model\n",
    "    \n",
    "        parameters:\n",
    "            A: (NxN) transition matrix in latent\n",
    "            B: (Nx1) projection matrix to latent\n",
    "            C: (1xN) projection matrix from latent to output\n",
    "            D: (1x1) skip connection from input to output\n",
    "            delta: time step, ensure sufficient smallness\n",
    "        \"\"\"\n",
    "        Cbar = C\n",
    "        Dbar = D\n",
    "        N = A.shape[0]\n",
    "        Bl = torch.linalg.inv(torch.eye(N) - delta / 2 * A)\n",
    "        Abar = Bl@(torch.eye(N) + delta/2 * A)\n",
    "        Bbar = Bl@(delta*B)\n",
    "        return Abar, Bbar, Cbar, Dbar\n",
    "\n",
    "    def scan_SSM(\n",
    "        self, Ab : torch.Tensor, Bb : torch.Tensor, Cb : torch.Tensor, Db : torch.Tensor,  u : torch.Tensor, x0 : torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        computes steps of the SSM going forward.\n",
    "    \n",
    "        parameters:\n",
    "            Ab : (NxN) transition matrix in discrete space of latent to latent\n",
    "            Bb : (Nx1) projcetion matrix from input to latent space\n",
    "            Cb : (1xN) projection matrix from latent to output\n",
    "            Db : (1x1) skip connection input to output\n",
    "            u  : (L,)  trajectory we are trying to track\n",
    "            x0 : (Nx1) initial condition of latent\n",
    "        \"\"\"\n",
    "        x0 = torch.zeros((10,1))\n",
    "        x = torch.zeros((Ab.shape[0], len(u[:100])))\n",
    "        y = torch.zeros_like(u[:100])\n",
    "        for i in range(u[:100].shape[0]):\n",
    "            x[:,i] = (Ab@x0 + Bb*u[i]).squeeze()\n",
    "            y[i] = (Cb@x[:,i]).squeeze()\n",
    "            x0 = x[:,i].unsqueeze(-1)\n",
    "        return x, y + Db*u\n",
    "        \n",
    "    def K_conv(self, Ab : torch.Tensor, Bb : torch.Tensor, Cb : torch.Tensor, L : int) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        computes convolution window given L time steps using equation K_t = Cb @ (Ab^t) @ Bb. \n",
    "        Needs to be flipped for correct causal convolution, but can be used as is in fft mode\n",
    "    \n",
    "        parameters:\n",
    "            Ab : transition matrix\n",
    "            Bb : projection matrix from input to latent\n",
    "            Cb : projection matrix from latent to input\n",
    "            Db : skip connection\n",
    "            L  : length over which we want convolutional window\n",
    "        \"\"\"\n",
    "        return torch.stack([(Cb @ torch.matrix_power(Ab, l) @ Bb).squeeze() for l in range(L)])\n",
    "\n",
    "    def causal_conv(self, u : torch.Tensor, K : torch.Tensor, notfft : bool = False) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        computes 1-d causal convolution either using standard method or fft transform.\n",
    "    \n",
    "        parameters:\n",
    "            u : trajectory to convolve\n",
    "            K : convolutional filter\n",
    "            notfft: boolean, for whether or not we use fft mode or not.\n",
    "        \"\"\"\n",
    "        assert K.shape==u.shape\n",
    "        \n",
    "        L = u.shape[0]\n",
    "        powers_of_2 = 2**int(math.ceil(math.log2(2*L)))\n",
    "    \n",
    "        if notfft:\n",
    "            padded_u = torch.nn.functional.pad(u, (L-1,L-1))\n",
    "            convolve = torch.zeros_like(u)\n",
    "            for i in range(L):\n",
    "                convolve[i] = torch.sum(padded_u[i:i+L]*K.flip(dims=[0]))\n",
    "            return convolve\n",
    "        else:\n",
    "    \n",
    "            K_pad = torch.nn.functional.pad(K, (0, L))\n",
    "            u_pad = torch.nn.functional.pad(u, (0, L))\n",
    "            \n",
    "            K_f, u_f = torch.fft.rfft(K_pad, n = powers_of_2), torch.fft.rfft(u_pad, n = powers_of_2)\n",
    "            return torch.fft.irfft(K_f * u_f, n = powers_of_2)[:L]\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        u : torch.Tensor,\n",
    "        x0 : torch.Tensor = torch.zeros((1,1)),\n",
    "        mode : bool | str = False\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        forward pass of model\n",
    "\n",
    "        Parameters:\n",
    "            u  : input time series\n",
    "            x0 : initial condition, only used in recurrent mode\n",
    "            mode: recurrent mode (\"recurrent\"), or convolution mode (True : direct convolution, False : fourier transform)\n",
    "        \"\"\"\n",
    "        if mode == \"recurrent\":\n",
    "            return self.scan_SSM(self.Abar, self.Bbar, self.Cbar, self.Dbar, u, x0)[1]\n",
    "        else:\n",
    "            K = self.K_conv(self.Abar, self.Bbar, self.Cbar, u.shape[0])\n",
    "            return self.causal_conv(u, K, mode) + self.D*u\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bca8c915-c671-48f6-b422-e86c02c00a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssm = SSMLayer(latent_dim=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a96299c2-8550-494d-a60d-0bac20d43cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 100\n",
    "num_steps = int(T/torch.exp(ssm.dt))\n",
    "\n",
    "\n",
    "u = torch.cos(torch.arange(num_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd5fb568-6b70-47a0-a1d1-c81362a20a00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000e+00,  0.0000e+00, -3.7253e-09, -1.4901e-08,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00, -7.4506e-09,  0.0000e+00,\n",
       "         -1.4901e-08, -1.1176e-08,  0.0000e+00, -2.9802e-08, -4.4703e-08,\n",
       "         -7.4506e-09, -1.4901e-08,  3.7253e-09,  0.0000e+00,  0.0000e+00,\n",
       "         -2.9802e-08, -5.9605e-08, -5.9605e-08,  0.0000e+00, -1.4901e-08,\n",
       "          5.9605e-08, -5.9605e-08, -1.3411e-07, -8.9407e-08,  1.4901e-08,\n",
       "         -5.9605e-08, -1.1921e-07, -1.1921e-07, -1.7881e-07,  0.0000e+00,\n",
       "         -8.9407e-08, -1.4901e-07, -5.9605e-08, -1.7881e-07, -1.7881e-07,\n",
       "         -1.1921e-07, -2.3842e-07, -1.1921e-07, -2.9802e-07,  0.0000e+00,\n",
       "          1.1921e-07, -2.3842e-07, -1.1921e-07, -1.7881e-07, -3.5763e-07,\n",
       "          0.0000e+00, -4.7684e-07, -2.3842e-07,  0.0000e+00,  0.0000e+00,\n",
       "         -7.1526e-07, -7.1526e-07, -4.7684e-07, -7.1526e-07, -2.3842e-07,\n",
       "          2.3842e-07, -7.1526e-07, -1.4305e-06, -1.9073e-06, -2.3842e-06,\n",
       "         -9.5367e-07,  0.0000e+00,  0.0000e+00, -1.9073e-06, -9.5367e-07,\n",
       "         -4.7684e-06, -1.9073e-06, -3.8147e-06, -9.5367e-07, -3.3379e-06,\n",
       "         -2.8610e-06, -5.7220e-06, -2.8610e-06,  1.9073e-06,  0.0000e+00,\n",
       "         -6.6757e-06, -6.6757e-06, -7.6294e-06, -3.8147e-06, -5.7220e-06,\n",
       "          3.8147e-06, -5.7220e-06, -2.2888e-05, -1.9073e-05, -1.9073e-05,\n",
       "         -1.9073e-05,  9.5367e-06, -7.6294e-06, -2.6703e-05, -3.4332e-05,\n",
       "         -3.4332e-05, -1.5259e-05, -3.4332e-05]], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssm(u[:100], torch.tensor(0), mode = \"recurrent\") - ssm(u[:100], torch.tensor(0), mode = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "583a0919-ac70-4d4a-bdc0-9e8eed07b575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-8.1658e-06, -4.2766e-06, -1.6805e-05, -1.6332e-05, -2.3991e-06,\n",
       "         -6.5565e-07,  6.2287e-06,  3.3379e-06, -1.2256e-05, -6.4373e-06,\n",
       "          6.6757e-06,  1.3277e-05,  2.6822e-06,  5.6326e-06,  2.2948e-06,\n",
       "          8.8215e-06,  1.8612e-05,  1.7304e-05,  1.4305e-05,  7.0930e-06,\n",
       "         -6.5267e-06, -3.2037e-06,  4.2319e-06,  1.0133e-05,  1.6272e-05,\n",
       "          1.3500e-05, -9.1195e-06, -7.7039e-06,  2.2352e-06,  2.6524e-06,\n",
       "          9.6858e-06,  6.0797e-06,  5.1856e-06,  2.3842e-07, -9.2089e-06,\n",
       "          3.6955e-06,  1.1057e-05,  1.0252e-05,  7.9274e-06,  8.2254e-06,\n",
       "          0.0000e+00,  1.1563e-05,  1.0788e-05,  1.9014e-05,  1.8716e-05,\n",
       "          1.5855e-05,  1.1325e-05,  1.3590e-05,  1.2457e-05,  1.0848e-05,\n",
       "          1.4544e-05,  8.5831e-06,  0.0000e+00, -2.6226e-06,  3.3379e-06,\n",
       "          8.5831e-06,  1.7405e-05,  1.6212e-05, -3.0994e-06, -4.5300e-06,\n",
       "         -5.0068e-06,  3.0994e-06,  6.1989e-06,  1.3351e-05,  3.5763e-06,\n",
       "         -2.8610e-06, -5.2452e-06,  8.1062e-06,  1.6212e-05,  1.7166e-05,\n",
       "         -1.9073e-06,  9.5367e-07, -7.1526e-06,  4.7684e-07,  1.0967e-05,\n",
       "          1.8120e-05,  1.8120e-05,  4.7684e-06, -4.7684e-06, -3.8147e-06,\n",
       "          6.6757e-06,  1.0490e-05,  9.5367e-06,  0.0000e+00, -9.5367e-06,\n",
       "          0.0000e+00,  3.8147e-06, -3.8147e-06,  1.1444e-05,  0.0000e+00,\n",
       "         -2.0981e-05,  3.8147e-06,  0.0000e+00, -7.6294e-06,  3.8147e-06,\n",
       "          7.6294e-06,  7.6294e-06, -1.5259e-05]], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssm(u[:100], torch.tensor(0), mode = False) - ssm(u[:100], torch.tensor(0), mode = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "856f2606-d5f3-4121-851e-a9b7acb7ccbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.0553e-01,  2.0511e-01, -6.2344e-02, -2.4922e-01, -1.8186e-01,\n",
       "          7.9826e-02,  2.9742e-01,  2.7322e-01,  3.2046e-02, -2.0160e-01,\n",
       "         -2.0990e-01,  1.8045e-02,  2.7619e-01,  3.3103e-01,  1.3630e-01,\n",
       "         -1.2446e-01, -2.0664e-01, -2.9377e-02,  2.5008e-01,  3.8102e-01,\n",
       "          2.4980e-01, -1.5628e-02, -1.6331e-01, -4.8881e-02,  2.3177e-01,\n",
       "          4.3070e-01,  3.7596e-01,  1.2974e-01, -6.8727e-02, -2.3030e-02,\n",
       "          2.3993e-01,  4.9478e-01,  5.2498e-01,  3.2201e-01,  9.3377e-02,\n",
       "          7.1912e-02,  3.0189e-01,  5.9849e-01,  7.1785e-01,  5.8151e-01,\n",
       "          3.4873e-01,  2.7027e-01,  4.5813e-01,  7.8279e-01,  9.9260e-01,\n",
       "          9.4544e-01,  7.3973e-01,  6.2429e-01,  7.6996e-01,  1.1130e+00,\n",
       "          1.4140e+00,  1.4788e+00,  1.3372e+00,  1.2163e+00,  1.3323e+00,\n",
       "          1.6926e+00,  2.0894e+00,  2.2918e+00,  2.2590e+00,  2.1785e+00,\n",
       "          2.2950e+00,  2.6865e+00,  3.1937e+00,  3.5677e+00,  3.7005e+00,\n",
       "          3.7258e+00,  3.8974e+00,  4.3581e+00,  5.0103e+00,  5.6074e+00,\n",
       "          5.9837e+00,  6.2083e+00,  6.5250e+00,  7.1307e+00,  7.9978e+00,\n",
       "          8.9028e+00,  9.6357e+00,  1.0197e+01,  1.0802e+01,  1.1687e+01,\n",
       "          1.2898e+01,  1.4254e+01,  1.5518e+01,  1.6624e+01,  1.7742e+01,\n",
       "          1.9133e+01,  2.0913e+01,  2.2959e+01,  2.5032e+01,  2.7004e+01,\n",
       "          2.8991e+01,  3.1258e+01,  3.3988e+01,  3.7129e+01,  4.0458e+01,\n",
       "          4.3805e+01,  4.7225e+01,  5.0971e+01]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssm(u[:100], torch.tensor(0), mode = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a7e278e-e0eb-4bec-8afb-f0bd25992783",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3055]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssm.Cbar@(ssm.Bbar * u[0]) + ssm.D * u[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5bb18f24-aed5-4634-8e9f-1bdd0e4abba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b2ef5f-d9f4-4701-9771-147ec9723edd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
