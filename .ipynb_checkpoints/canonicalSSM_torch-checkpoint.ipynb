{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "baaff332-22f6-4ed0-a94f-9d19b068770b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "from collections.abc import Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "2ed1d768-e46f-4911-9e30-9d6091aded87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_SSM(N : int) -> (torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor):\n",
    "    A = torch.autograd.Variable(torch.rand(size=(N,N)), requires_grad = True)\n",
    "    B = torch.autograd.Variable(torch.rand(size=(N,1)), requires_grad = True)\n",
    "    C = torch.autograd.Variable(torch.rand(size=(1,N)), requires_grad = True)\n",
    "    D = torch.autograd.Variable(torch.rand(size=(1,1)), requires_grad = True)\n",
    "    return A, B, C, D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "c913ebed-b17c-4993-a4c4-be749db92f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "A, B, C, D = random_SSM(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "34e5a72b-292c-43a7-bda5-6edbf96b7ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = torch.zeros((1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "f60b605e-0171-4aec-acd1-793ea3007d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = torch.tensor(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "53248f90-d07b-45a7-b111-d45f5b2f6f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretize(\n",
    "    A : torch.Tensor, B : torch.Tensor, C : torch.Tensor, D : torch.Tensor, delta : torch.Tensor\n",
    ") -> (torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor):\n",
    "    \"\"\"Discretizes SSM using bilinear model\n",
    "\n",
    "    parameters:\n",
    "        A: (NxN) transition matrix in latent\n",
    "        B: (Nx1) projection matrix to latent\n",
    "        C: (1xN) projection matrix from latent to output\n",
    "        D: (1x1) skip connection from input to output\n",
    "        delta: time step, ensure sufficient smallness\n",
    "    \"\"\"\n",
    "    Cbar = C\n",
    "    Dbar = D\n",
    "    N = A.shape[0]\n",
    "    Bl = torch.linalg.inv(torch.eye(N) - delta / 2 * A)\n",
    "    Abar = Bl@(torch.eye(N) + delta/2 * A)\n",
    "    Bbar = Bl@(delta*B)\n",
    "    return Abar, Bbar, Cbar, Dbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "3305b7a1-5b3e-4abc-8d77-f34f8a399075",
   "metadata": {},
   "outputs": [],
   "source": [
    "Abar, Bbar, Cbar, Dbar = discretize(A, B, C, D, delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "d72635d9-919f-4482-a03c-c6a364503b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 100\n",
    "num_steps = int(T/delta)\n",
    "\n",
    "u = torch.cos(torch.arange(num_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "c3134525-8e1e-40be-b02b-346dcbb7bb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scan_SSM(\n",
    "    Ab : torch.Tensor, Bb : torch.Tensor, Cb : torch.Tensor, Db : torch.Tensor,  u : torch.Tensor, x0 : torch.Tensor\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    computes steps of the SSM going forward.\n",
    "\n",
    "    parameters:\n",
    "        Ab : (NxN) transition matrix in discrete space of latent to latent\n",
    "        Bb : (Nx1) projcetion matrix from input to latent space\n",
    "        Cb : (1xN) projection matrix from latent to output\n",
    "        Db : (1x1) skip connection input to output\n",
    "        u  : (L,)  trajectory we are trying to track\n",
    "        x0 : (Nx1) initial condition of latent\n",
    "    \"\"\"\n",
    "    x0 = torch.zeros((10,1))\n",
    "    x = torch.zeros((Ab.shape[0], len(u[:100])))\n",
    "    y = torch.zeros_like(u[:100])\n",
    "    for i in range(u[:100].shape[0]):\n",
    "        x[:,i] = (Ab@x0 + Bb*u[i]).squeeze()\n",
    "        y[i] = (Cb@x[:,i]).squeeze()\n",
    "        x0 = x[:,i].unsqueeze(-1)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "397018e5-477a-4464-875d-00e7156dcc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def K_conv(Ab : torch.Tensor, Bb : torch.Tensor, Cb : torch.Tensor, L : int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    computes convolution window given L time steps using equation K_t = Cb @ (Ab^t) @ Bb. \n",
    "    Needs to be flipped for correct causal convolution, but can be used as is in fft mode\n",
    "\n",
    "    parameters:\n",
    "        Ab : transition matrix\n",
    "        Bb : projection matrix from input to latent\n",
    "        Cb : projection matrix from latent to input\n",
    "        Db : skip connection\n",
    "        L  : length over which we want convolutional window\n",
    "    \"\"\"\n",
    "    return torch.stack([(Cb @ torch.matrix_power(Ab, l) @ Bb).squeeze() for l in range(L)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "e4daebfc-d2d8-41b9-8599-4ddd690b3485",
   "metadata": {},
   "outputs": [],
   "source": [
    "def causal_conv(u : torch.Tensor, K : torch.Tensor, notfft : bool = False) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    computes 1-d causal convolution either using standard method or fft transform.\n",
    "\n",
    "    parameters:\n",
    "        u : trajectory to convolve\n",
    "        K : convolutional filter\n",
    "        notfft: boolean, for whether or not we use fft mode or not.\n",
    "    \"\"\"\n",
    "    assert len(u.shape)==1\n",
    "    assert K.shape==u.shape\n",
    "    \n",
    "    L = u.shape[0]\n",
    "    powers_of_2 = 2**int(math.ceil(math.log2(2*L)))\n",
    "\n",
    "    if notfft:\n",
    "        padded_u = torch.nn.functional.pad(u, (L-1,L-1))\n",
    "        convolve = torch.zeros_like(u)\n",
    "        for i in range(L):\n",
    "            convolve[i] = torch.sum(padded_u[i:i+L]*K.flip(dims=[0]))\n",
    "        return convolve\n",
    "    else:\n",
    "\n",
    "        K_pad = torch.nn.functional.pad(K, (0, L))\n",
    "        u_pad = torch.nn.functional.pad(u, (0, L))\n",
    "        \n",
    "        K_f, u_f = torch.fft.rfft(K_pad, n = powers_of_2), torch.fft.rfft(u_pad, n = powers_of_2)\n",
    "        return torch.fft.irfft(K_f * u_f, n = powers_of_2)[:L]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "f0d3efcc-e3f7-43ca-bda3-7601774fd727",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = K_conv(Abar, Bbar, Cbar, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "6f74b795-1716-45f9-8c7e-3be76d1a88e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_fft = causal_conv(u[:100], K)\n",
    "conv_notfft = causal_conv(u[:100],K , notfft=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "6f4895f0-52c5-444c-9837-f90d033de1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = scan_SSM(Abar, Bbar, Cbar, Dbar, u[:100], torch.zeros((10,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "baa14979-dfe1-41e2-b0ae-9834511822a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(True)\n",
      "tensor(True)\n"
     ]
    }
   ],
   "source": [
    "print((abs(conv_fft - conv_notfft)<1e-5).all())\n",
    "print((abs(conv_fft - y)<1e-5).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "d10407bf-c7b7-41c6-84e8-f843de2525b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8434])"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "ad8c56ba-ea9b-4ed5-bb0a-82539bd529b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_step_initializer(dt_min = 0.001, dt_max = 0.1):\n",
    "    \"\"\"\n",
    "    initial guess for dt, from random number generator. to be learned.\n",
    "\n",
    "    parameters:\n",
    "        dt_min\n",
    "        dt_max\n",
    "    \"\"\"\n",
    "    return torch.autograd.Variable(torch.rand(1) * (torch.log(dt_max) - torch.log(dt_min)) + torch.log(dt_min), requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "47782377-fad9-4f35-a7c5-4c12a7ffbdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SSMLayer(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Simple layer that does SSMing. Assumes single input, single output. \n",
    "    Could be made multi-dimensional either by stacking and decorrelating,\n",
    "    or by playing with the code to allow for multi input, multioutput. Should be relatively easy, \n",
    "    but need to carefully think a little about convolution of multi dim inputs.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        latent_dim,\n",
    "        L_max,\n",
    "        dt_min = 0.001,\n",
    "        dt_max = 0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.A, self.B, self.C, self.D = self.random_SSM(latent_dim)\n",
    "        self.Abar, self.Bbar, self.Cbar, self.Dbar = self.discretize(self.A, self.B, self.C, self.D, self.dt)\n",
    "        self.dt = self.log_step_initializer(dt_min, dt_max)\n",
    "\n",
    "    def random_SSM(\n",
    "        self, \n",
    "        N : int\n",
    "    ) -> (torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor):\n",
    "        \"\"\"\n",
    "        initializing SSM parameters given latent dim\n",
    "        \n",
    "        parameters:\n",
    "            N : size of latent dimension\n",
    "        \"\"\"\n",
    "        A = torch.autograd.Variable(torch.rand(size=(N,N)), requires_grad = True)\n",
    "        B = torch.autograd.Variable(torch.rand(size=(N,1)), requires_grad = True)\n",
    "        C = torch.autograd.Variable(torch.rand(size=(1,N)), requires_grad = True)\n",
    "        D = torch.autograd.Variable(torch.rand(size=(1,1)), requires_grad = True)\n",
    "        return A, B, C, D\n",
    "\n",
    "    def log_step_initializer(self, dt_min = 0.001, dt_max = 0.1):\n",
    "        \"\"\"\n",
    "        initial guess for dt, from random number generator. to be learned.\n",
    "    \n",
    "        parameters:\n",
    "            dt_min\n",
    "            dt_max\n",
    "        \"\"\"\n",
    "        return torch.autograd.Variable(torch.rand(1) * (torch.log(dt_max) - torch.log(dt_min)) + torch.log(dt_min), requires_grad = True)\n",
    "\n",
    "    def discretize(\n",
    "        self, A : torch.Tensor, B : torch.Tensor, C : torch.Tensor, D : torch.Tensor, delta : torch.Tensor\n",
    "    ) -> (torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor):\n",
    "        \"\"\"Discretizes SSM using bilinear model\n",
    "    \n",
    "        parameters:\n",
    "            A: (NxN) transition matrix in latent\n",
    "            B: (Nx1) projection matrix to latent\n",
    "            C: (1xN) projection matrix from latent to output\n",
    "            D: (1x1) skip connection from input to output\n",
    "            delta: time step, ensure sufficient smallness\n",
    "        \"\"\"\n",
    "        Cbar = C\n",
    "        Dbar = D\n",
    "        N = A.shape[0]\n",
    "        Bl = torch.linalg.inv(torch.eye(N) - delta / 2 * A)\n",
    "        Abar = Bl@(torch.eye(N) + delta/2 * A)\n",
    "        Bbar = Bl@(delta*B)\n",
    "        return Abar, Bbar, Cbar, Dbar\n",
    "\n",
    "    def scan_SSM(\n",
    "        self, Ab : torch.Tensor, Bb : torch.Tensor, Cb : torch.Tensor, Db : torch.Tensor,  u : torch.Tensor, x0 : torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        computes steps of the SSM going forward.\n",
    "    \n",
    "        parameters:\n",
    "            Ab : (NxN) transition matrix in discrete space of latent to latent\n",
    "            Bb : (Nx1) projcetion matrix from input to latent space\n",
    "            Cb : (1xN) projection matrix from latent to output\n",
    "            Db : (1x1) skip connection input to output\n",
    "            u  : (L,)  trajectory we are trying to track\n",
    "            x0 : (Nx1) initial condition of latent\n",
    "        \"\"\"\n",
    "        x0 = torch.zeros((10,1))\n",
    "        x = torch.zeros((Ab.shape[0], len(u[:100])))\n",
    "        y = torch.zeros_like(u[:100])\n",
    "        for i in range(u[:100].shape[0]):\n",
    "            x[:,i] = (Ab@x0 + Bb*u[i]).squeeze()\n",
    "            y[i] = (Cb@x[:,i]).squeeze()\n",
    "            x0 = x[:,i].unsqueeze(-1)\n",
    "        return x, y\n",
    "        \n",
    "    def K_conv(self, Ab : torch.Tensor, Bb : torch.Tensor, Cb : torch.Tensor, L : int) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        computes convolution window given L time steps using equation K_t = Cb @ (Ab^t) @ Bb. \n",
    "        Needs to be flipped for correct causal convolution, but can be used as is in fft mode\n",
    "    \n",
    "        parameters:\n",
    "            Ab : transition matrix\n",
    "            Bb : projection matrix from input to latent\n",
    "            Cb : projection matrix from latent to input\n",
    "            Db : skip connection\n",
    "            L  : length over which we want convolutional window\n",
    "        \"\"\"\n",
    "        return torch.stack([(Cb @ torch.matrix_power(Ab, l) @ Bb).squeeze() for l in range(L)])\n",
    "\n",
    "    def causal_conv(u : torch.Tensor, K : torch.Tensor, notfft : bool = False) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        computes 1-d causal convolution either using standard method or fft transform.\n",
    "    \n",
    "        parameters:\n",
    "            u : trajectory to convolve\n",
    "            K : convolutional filter\n",
    "            notfft: boolean, for whether or not we use fft mode or not.\n",
    "        \"\"\"\n",
    "        assert K.shape==u.shape\n",
    "        \n",
    "        L = u.shape[0]\n",
    "        powers_of_2 = 2**int(math.ceil(math.log2(2*L)))\n",
    "    \n",
    "        if notfft:\n",
    "            padded_u = torch.nn.functional.pad(u, (L-1,L-1))\n",
    "            convolve = torch.zeros_like(u)\n",
    "            for i in range(L):\n",
    "                convolve[i] = torch.sum(padded_u[i:i+L]*K.flip(dims=[0]))\n",
    "            return convolve\n",
    "        else:\n",
    "    \n",
    "            K_pad = torch.nn.functional.pad(K, (0, L))\n",
    "            u_pad = torch.nn.functional.pad(u, (0, L))\n",
    "            \n",
    "            K_f, u_f = torch.fft.rfft(K_pad, n = powers_of_2), torch.fft.rfft(u_pad, n = powers_of_2)\n",
    "            return torch.fft.irfft(K_f * u_f, n = powers_of_2)[:L]\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        u : torch.Tensor,\n",
    "        x0 : torch.Tensor = torch.zeros((1,1)),\n",
    "        mode : bool | str = False\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        forward pass of model\n",
    "\n",
    "        Parameters:\n",
    "            u  : input time series\n",
    "            x0 : initial condition, only used in recurrent mode\n",
    "            mode: recurrent mode (\"recurrent\"), or convolution mode (True : direct convolution, False : fourier transform)\n",
    "        \"\"\"\n",
    "        if mode == \"recurrent\":\n",
    "            return self.scan_SSM(self.Abar, self.Bbar, self.Cbar, u, x0)[1]\n",
    "        else:\n",
    "            K = self.K_conv(self.Abar, self.Bbar, self.Cbar, u.shape[0])\n",
    "            return self.causal_conv(u, K, mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "5306197b-fa32-44f1-a7b3-6a2c61c0675d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_HiPPO(N : int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    creates HiPPO matrix for legendre polynomials up to order N\n",
    "    parameters:\n",
    "        N: int\n",
    "    \"\"\"\n",
    "    P = torch.sqrt(1+2*torch.arange(N))\n",
    "    A = P.unsqueeze(1) * P.unsqueeze(0)\n",
    "    A = torch.tril(A) - torch.diag(torch.arange(N))\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "71aa99a8-a247-4d94-b7c3-93ac93bbbf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def K_gen_inverse(\n",
    "    Abar : torch.Tensor, Bbar : torch.Tensor, Cbar : torch.Tensor, L : int\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    creates generating function for convolutional window, to be evaluated at roots of unity\n",
    "    parameters:\n",
    "        Abar : discretized A matrix\n",
    "        Bbar : discretized B matrix\n",
    "        Cbar : discretized C matrix\n",
    "        L    : length of convolutional window\n",
    "    \"\"\"\n",
    "    Abar = Abar.to(torch.complex64)\n",
    "    Bbar = Bbar.to(torch.complex64)\n",
    "    Cbar = Cbar.to(torch.complex64)\n",
    "    \n",
    "    I = torch.eye(Abar.shape[0]).to(torch.complex64)\n",
    "    Al = torch.matrix_power(Abar, L)\n",
    "    Ctilde = Cbar @ (I - (Al))\n",
    "    return lambda z: (torch.conj(Ctilde)@(torch.linalg.inv(I-Abar * z))@Bbar).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "b6cb82c4-1cc6-4299-8cb0-0d899af52df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "blah = K_gen_inverse(Abar, Bbar, Cbar, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "df1588d6-0b86-4156-bae5-29bea50245e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0019, grad_fn=<SqueezeBackward0>)"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blah(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "ddce6900-8991-4cf9-ac63-9b2159051b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_from_gen(gen : Callable, L : int):\n",
    "    \"\"\"\n",
    "    returns convolution from generating function by evaluating at roots of unity\n",
    "\n",
    "    parameters:\n",
    "        gen : generating function\n",
    "        L   : int\n",
    "    \"\"\"\n",
    "    omega_L = torch.exp(-2j * torch.pi * torch.arange(L)/L)\n",
    "    atRoots = torch.tensor([gen(omega) for omega in omega_L])\n",
    "    return torch.fft.irfft(atRoots, L).squeeze()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "f0ac07d4-17d1-442f-a5c4-3e2cb343dfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "blah = K_gen_inverse(Abar, Bbar, Cbar, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "4218dd6f-6ae6-471b-a78b-49a56bdce711",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expected m1 and m2 to have the same dtype, but got: float != c10::complex<float>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[316], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mconv_from_gen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblah\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[314], line 10\u001b[0m, in \u001b[0;36mconv_from_gen\u001b[0;34m(gen, L)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mreturns convolution from generating function by evaluating at roots of unity\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;03m    L   : int\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      9\u001b[0m omega_L \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39mj \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mpi \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(L)\u001b[38;5;241m/\u001b[39mL)\n\u001b[0;32m---> 10\u001b[0m atRoots \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[43m[\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m(\u001b[49m\u001b[43momega\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43momega\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43momega_L\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mfft\u001b[38;5;241m.\u001b[39mirfft(atRoots, L)\u001b[38;5;241m.\u001b[39msqueeze()\n",
      "Cell \u001b[0;32mIn[314], line 10\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mreturns convolution from generating function by evaluating at roots of unity\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;03m    L   : int\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      9\u001b[0m omega_L \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39mj \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mpi \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(L)\u001b[38;5;241m/\u001b[39mL)\n\u001b[0;32m---> 10\u001b[0m atRoots \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[43mgen\u001b[49m\u001b[43m(\u001b[49m\u001b[43momega\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m omega \u001b[38;5;129;01min\u001b[39;00m omega_L])\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mfft\u001b[38;5;241m.\u001b[39mirfft(atRoots, L)\u001b[38;5;241m.\u001b[39msqueeze()\n",
      "Cell \u001b[0;32mIn[307], line 15\u001b[0m, in \u001b[0;36mK_gen_inverse.<locals>.<lambda>\u001b[0;34m(z)\u001b[0m\n\u001b[1;32m     13\u001b[0m Al \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatrix_power(Abar, L)\n\u001b[1;32m     14\u001b[0m Ctilde \u001b[38;5;241m=\u001b[39m Cbar \u001b[38;5;241m@\u001b[39m (I \u001b[38;5;241m-\u001b[39m (Al))\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mlambda\u001b[39;00m z: (\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCtilde\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mI\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mAbar\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;129m@Bbar\u001b[39m)\u001b[38;5;241m.\u001b[39msqueeze()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expected m1 and m2 to have the same dtype, but got: float != c10::complex<float>"
     ]
    }
   ],
   "source": [
    "conv_from_gen(blah, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "11e402e7-33bf-49d4-9ef3-ab78996fa728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3.2026e-02,  5.0786e-02,  3.9775e-02,  9.8948e-03, -1.0565e-02,\n",
       "        -1.9345e-03,  2.8752e-02,  5.4227e-02,  5.2064e-02,  2.5292e-02,\n",
       "        -3.7849e-04, -1.9813e-04,  2.6874e-02,  5.7214e-02,  6.4257e-02,\n",
       "         4.2923e-02,  1.4292e-02,  6.2244e-03,  2.7753e-02,  6.0778e-02,\n",
       "         7.6717e-02,  6.2783e-02,  3.3747e-02,  1.8364e-02,  3.2938e-02,\n",
       "         6.6338e-02,  9.0239e-02,  8.5166e-02,  5.8408e-02,  3.7322e-02,\n",
       "         4.4187e-02,  7.5728e-02,  1.0613e-01,  1.1080e-01,  8.8944e-02,\n",
       "         6.4354e-02,  6.3508e-02,  9.1249e-02,  1.2634e-01,  1.4100e-01,\n",
       "         1.2645e-01,  1.0101e-01,  9.3246e-02,  1.1574e-01,  1.5352e-01,\n",
       "         1.7785e-01,  1.7265e-01,  1.4932e-01,  1.3624e-01,  1.5272e-01,\n",
       "         1.9126e-01,  2.2445e-01,  2.3020e-01,  2.1207e-01,  1.9601e-01,\n",
       "         2.0654e-01,  2.4420e-01,  2.8512e-01,  3.0295e-01,  2.9313e-01,\n",
       "         2.7713e-01,  2.8270e-01,  3.1842e-01,  3.6582e-01,  3.9643e-01,\n",
       "         3.9794e-01,  3.8560e-01,  3.8822e-01,  4.2172e-01,  4.7455e-01,\n",
       "         5.1834e-01,  5.3404e-01,  5.2948e-01,  5.3223e-01,  5.6429e-01,\n",
       "         6.2195e-01,  6.7923e-01,  7.1186e-01,  7.1964e-01,  7.2669e-01,\n",
       "         7.5939e-01,  8.2213e-01,  8.9343e-01,  9.4573e-01,  9.7082e-01,\n",
       "         9.8752e-01,  1.0244e+00,  1.0937e+00,  1.1802e+00,  1.2551e+00,\n",
       "         1.3031e+00,  1.3359e+00,  1.3824e+00,  1.4614e+00,  1.5652e+00,\n",
       "         1.6664e+00,  1.7434e+00,  1.8004e+00,  1.8637e+00,  1.9578e+00],\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_fft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "8b000878-1875-48ee-92e9-6f025776ac51",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = make_HiPPO(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "86b26dc6-cb55-4d8a-8909-58d9f9873d53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-9.5394)"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A[6,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "314bfe8d-335b-47c5-a89a-a04a4923a4ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -1.0000,  -0.0000,  -0.0000,  -0.0000,  -0.0000,  -0.0000,  -0.0000,\n",
       "          -0.0000,  -0.0000,  -0.0000],\n",
       "        [ -1.7321,  -2.0000,  -0.0000,  -0.0000,  -0.0000,  -0.0000,  -0.0000,\n",
       "          -0.0000,  -0.0000,  -0.0000],\n",
       "        [ -2.2361,  -3.8730,  -3.0000,  -0.0000,  -0.0000,  -0.0000,  -0.0000,\n",
       "          -0.0000,  -0.0000,  -0.0000],\n",
       "        [ -2.6458,  -4.5826,  -5.9161,  -4.0000,  -0.0000,  -0.0000,  -0.0000,\n",
       "          -0.0000,  -0.0000,  -0.0000],\n",
       "        [ -3.0000,  -5.1962,  -6.7082,  -7.9373,  -5.0000,  -0.0000,  -0.0000,\n",
       "          -0.0000,  -0.0000,  -0.0000],\n",
       "        [ -3.3166,  -5.7446,  -7.4162,  -8.7750,  -9.9499,  -6.0000,  -0.0000,\n",
       "          -0.0000,  -0.0000,  -0.0000],\n",
       "        [ -3.6056,  -6.2450,  -8.0623,  -9.5394, -10.8167, -11.9583,  -7.0000,\n",
       "          -0.0000,  -0.0000,  -0.0000],\n",
       "        [ -3.8730,  -6.7082,  -8.6603, -10.2470, -11.6189, -12.8452, -13.9642,\n",
       "          -8.0000,  -0.0000,  -0.0000],\n",
       "        [ -4.1231,  -7.1414,  -9.2195, -10.9087, -12.3693, -13.6748, -14.8661,\n",
       "         -15.9687,  -9.0000,  -0.0000],\n",
       "        [ -4.3589,  -7.5498,  -9.7468, -11.5326, -13.0767, -14.4568, -15.7162,\n",
       "         -16.8819, -17.9722, -10.0000]])"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "238adc62-1757-43ac-a934-1e80d67fc950",
   "metadata": {},
   "outputs": [],
   "source": [
    "P = torch.sqrt(1+2*torch.arange(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "54b9e610-33b6-40e2-ab9e-9d8335cf02eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = torch.tril(P.unsqueeze(1) * P.unsqueeze(0)) - torch.diag(torch.arange(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "a8a73ef9-c370-48a8-b170-0fd44bbd0303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(17.9722)"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[9,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "4efadc38-8252-43f0-844b-2be6f00f9d9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.972200755611432"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(2*9+1)**(1/2) * (2*8+1)**(1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "435f361c-bebd-433b-a94d-7fe5122694ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000],\n",
       "        [ 1.7321,  2.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000],\n",
       "        [ 2.2361,  3.8730,  3.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000],\n",
       "        [ 2.6458,  4.5826,  5.9161,  4.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000],\n",
       "        [ 3.0000,  5.1962,  6.7082,  7.9373,  5.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000],\n",
       "        [ 3.3166,  5.7446,  7.4162,  8.7750,  9.9499,  6.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000],\n",
       "        [ 3.6056,  6.2450,  8.0623,  9.5394, 10.8167, 11.9583,  7.0000,  0.0000,\n",
       "          0.0000,  0.0000],\n",
       "        [ 3.8730,  6.7082,  8.6603, 10.2470, 11.6189, 12.8452, 13.9642,  8.0000,\n",
       "          0.0000,  0.0000],\n",
       "        [ 4.1231,  7.1414,  9.2195, 10.9087, 12.3693, 13.6748, 14.8661, 15.9687,\n",
       "          9.0000,  0.0000],\n",
       "        [ 4.3589,  7.5498,  9.7468, 11.5326, 13.0767, 14.4568, 15.7162, 16.8819,\n",
       "         17.9722, 10.0000]])"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4606f8b-22a8-479b-abbf-0ef619b4e716",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
